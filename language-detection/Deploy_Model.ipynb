{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# create environment for the deploy\n",
        "import mlflow\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.webservice import AciWebservice\n",
        "import uuid\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.model import Model\n",
        "\n",
        "from random import shuffle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "\n",
        "\n",
        "# Models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Metrics\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1649736420506
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to your workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# create experiment and start logging to a new run in the experiment\n",
        "experiment_name = \"detect-lang-rf\"\n",
        "\n",
        "# set up MLflow to track the metrics\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "mlflow.set_experiment(experiment_name)\n",
        "mlflow.autolog()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022/04/12 04:07:02 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of statsmodels. If you encounter errors during autologging, try upgrading / downgrading statsmodels to a supported version, or try upgrading MLflow.\n2022/04/12 04:07:02 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n2022/04/12 04:07:02 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n2022/04/12 04:07:02 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n2022/04/12 04:07:02 INFO mlflow.pyspark.ml: No SparkSession detected. Autologging will log pyspark.ml models contained in the default allowlist. To specify a custom allowlist, initialize a SparkSession prior to calling mlflow.pyspark.ml.autolog() and specify the path to your allowlist file via the spark.mlflow.pysparkml.autolog.logModelAllowlistFile conf.\n2022/04/12 04:07:02 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649736422515
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Definitions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove some special characters\n",
        "def remove_special_chars(sen, filter_chars):\n",
        "    sen = sen.strip()\n",
        "    sen = sen.lower()\n",
        "    for each in sen:\n",
        "        num_ascii = ord(each)\n",
        "        # delete number, \".\", \"\\\", all chars in filter_chars\n",
        "        if (num_ascii > 47 and num_ascii < 58) or num_ascii == 92 or num_ascii == 46 or (each in filter_chars):\n",
        "            sen = sen.replace(each, \"\")\n",
        "    return sen\n",
        "\n",
        "# read file csv and convert it to pandasframe\n",
        "def open_file(name):\n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    with open('{file_name}.csv'.format(file_name = \"formatted_data\"), encoding='Latin1') as f:\n",
        "        content = f.readlines()\n",
        "    # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
        "    content = [x.strip() for x in content] # mỗi\n",
        "\n",
        "    data = []\n",
        "    for num, each in enumerate(content):\n",
        "        each = each.split(\";\")\n",
        "\n",
        "        if \".\" in each[1]:\n",
        "            sentences = each[1].split(\".\") \n",
        "            filter_chars = ['\\t', '!', '\"', '%', '&', '*', '+', ',', '-', '/', ':', '=', '?', '@', '[', ']', '§', \n",
        "                            '«', \"”\", \"\\\\\", \".\", '»']\n",
        "                    \n",
        "            for number, sen in enumerate(sentences):\n",
        "                \"\"\"\n",
        "                insert remove special characters\n",
        "\n",
        "                \"\"\"\n",
        "\n",
        "                # filter no meaning words\n",
        "                sen = remove_special_chars(sen, filter_chars)\n",
        "\n",
        "                # make sure a sentence have len(sentence) > 0\n",
        "                if len(sen)>0:\n",
        "                    data.append([each[0], sen, each[2]])\n",
        "\n",
        "        else:\n",
        "            data.append(each)\n",
        "\n",
        "    main_data = data[1:]\n",
        "    main_data = shuffle(main_data)\n",
        "    df = pd.DataFrame(main_data, columns = data[0])\n",
        "    return df\n",
        "\n",
        "# get data in a row\n",
        "def get_data(df, row = 60000):\n",
        "    return  df.iloc[row][0], df.iloc[row][1]\n",
        "\n",
        "# vectorize sentences and split it in to train and test file\n",
        "def vectorization(df, test_size=0.2):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(list(df[\"text\"]), list(df[\"language\"]), test_size=test_size, random_state=42)\n",
        "\n",
        "    # vectorize sentence X\n",
        "    count_vectorizer = CountVectorizer(analyzer='char')\n",
        "    X_train_features = count_vectorizer.fit_transform(X_train)\n",
        "    X_test_features = count_vectorizer.transform(X_test)\n",
        "\n",
        "    # vectorize label Y\n",
        "    label_encoder = preprocessing.LabelEncoder()\n",
        "    y_train_features = label_encoder.fit_transform(y_train)\n",
        "    y_test_features = label_encoder.transform(y_test)\n",
        "    \n",
        "    # getted features\n",
        "    features = count_vectorizer.get_feature_names()\n",
        "    \n",
        "    # getted labels\n",
        "    labels = list(label_encoder.classes_)\n",
        "    \n",
        "    return X_train_features, y_train_features, X_test_features, y_test_features, features, labels, count_vectorizer"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649736454205
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Split Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = open_file('formatted_data')\n",
        "X_train_features, y_train_features, X_test_features, y_test_features, features, labels, count_vectorizer = vectorization(df)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649736466593
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "      language                                               text length_text\n0           es  mi pregunta se refiere en primer lugar a las p...      733658\n1           it  soltanto in questo modo le parti lese possono ...      729712\n2           da  under nã¦ste runde af eu s strukturfonde  vil ...      678400\n3           de  schlieãlich fordern sie auch eine verbesserun...      747690\n4           sv  men samtidigt ã¤r det viktigt att fã¶rhindra a...      674945\n...        ...                                                ...         ...\n78155       da  jeg vil gerne lykã¸nske ham desvã¦rre er han i...      678400\n78156       hu                              szabã¡lyra hivatkozik      330524\n78157       es  en primer lugar la inmunidad de los funcionari...      733658\n78158       fi  olen myã¶s jã¤ttã¤nyt eddryhmã¤n puolesta asia...      694523\n78159       cs  opravy hlasovã¡nã­ a sdälenã­ o ãºmyslu hlaso...      317927\n\n[78160 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>language</th>\n      <th>text</th>\n      <th>length_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>es</td>\n      <td>mi pregunta se refiere en primer lugar a las p...</td>\n      <td>733658</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>it</td>\n      <td>soltanto in questo modo le parti lese possono ...</td>\n      <td>729712</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>da</td>\n      <td>under nã¦ste runde af eu s strukturfonde  vil ...</td>\n      <td>678400</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>de</td>\n      <td>schlieãlich fordern sie auch eine verbesserun...</td>\n      <td>747690</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sv</td>\n      <td>men samtidigt ã¤r det viktigt att fã¶rhindra a...</td>\n      <td>674945</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78155</th>\n      <td>da</td>\n      <td>jeg vil gerne lykã¸nske ham desvã¦rre er han i...</td>\n      <td>678400</td>\n    </tr>\n    <tr>\n      <th>78156</th>\n      <td>hu</td>\n      <td>szabã¡lyra hivatkozik</td>\n      <td>330524</td>\n    </tr>\n    <tr>\n      <th>78157</th>\n      <td>es</td>\n      <td>en primer lugar la inmunidad de los funcionari...</td>\n      <td>733658</td>\n    </tr>\n    <tr>\n      <th>78158</th>\n      <td>fi</td>\n      <td>olen myã¶s jã¤ttã¤nyt eddryhmã¤n puolesta asia...</td>\n      <td>694523</td>\n    </tr>\n    <tr>\n      <th>78159</th>\n      <td>cs</td>\n      <td>opravy hlasovã¡nã­ a sdälenã­ o ãºmyslu hlaso...</td>\n      <td>317927</td>\n    </tr>\n  </tbody>\n</table>\n<p>78160 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649739253750
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model: Random Forest Classifier"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create random forest model with the optimal parametter\n",
        "optimal_modelRF=RandomForestClassifier(n_estimators=300, max_features= 'log2')\n",
        "\n",
        "#Train the model using the training sets \n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649736466660
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "with mlflow.start_run() as run:\n",
        "    optimal_modelRF.fit(X_train_features,y_train_features)\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649736725691
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# register the model\n",
        "model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
        "model = mlflow.register_model(model_uri, \"lang-det-rf-model\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Registered model 'lang-det-rf-model' already exists. Creating a new version of this model...\n2022/04/12 04:12:06 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: lang-det-rf-model, version 2\nCreated version '2' of model 'lang-det-rf-model'.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649736726297
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get a curated environment\n",
        "env = Environment.get(\n",
        "    workspace=ws, \n",
        "    name=\"myenv\",\n",
        "    version=3\n",
        ")\n",
        "env.inferencing_stack_version='latest'\n",
        "\n",
        "# create deployment config i.e. compute resources\n",
        "aciconfig = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=2,\n",
        "    memory_gb=2,\n",
        "    tags={\"data\": \"languages\", \"method\": \"sklearn\"},\n",
        "    description=\"Predict Language with sklearn\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649736726394
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# get the registered model\n",
        "model = Model(ws, \"lang-det-rf-model\")\n",
        "\n",
        "# create an inference config i.e. the scoring script and environment\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
        "\n",
        "# deploy the service\n",
        "service_name = \"sklearn-langdet-svc-\" + str(uuid.uuid4())[:4]\n",
        "service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=service_name,\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=aciconfig,\n",
        ")\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}