{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "\n",
        "from random import shuffle\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "\n",
        "\n",
        "# Models\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<style>.container { width:100% !important; }</style>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1649664967929
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Functions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove some special characters\n",
        "def remove_special_chars(sen, filter_chars):\n",
        "    sen = sen.strip()\n",
        "    sen = sen.lower()\n",
        "    for each in sen:\n",
        "        num_ascii = ord(each)\n",
        "        # delete number, \".\", \"\\\", all chars in filter_chars\n",
        "        if (num_ascii > 47 and num_ascii < 58) or num_ascii == 92 or num_ascii == 46 or (each in filter_chars):\n",
        "            sen = sen.replace(each, \"\")\n",
        "    return sen\n",
        "\n",
        "# read file csv and convert it to pandasframe\n",
        "def open_file(name):\n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    with open('{file_name}.csv'.format(file_name = \"formatted_data\"), encoding='Latin1') as f:\n",
        "        content = f.readlines()\n",
        "    # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
        "    content = [x.strip() for x in content] # mỗi\n",
        "\n",
        "    data = []\n",
        "    for num, each in enumerate(content):\n",
        "        each = each.split(\";\")\n",
        "\n",
        "        if \".\" in each[1]:\n",
        "            sentences = each[1].split(\".\") \n",
        "            filter_chars = ['\\t', '!', '\"', '%', '&', '*', '+', ',', '-', '/', ':', '=', '?', '@', '[', ']', '§', \n",
        "                            '«', \"”\", \"\\\\\", \".\", '»']\n",
        "                    \n",
        "            for number, sen in enumerate(sentences):\n",
        "                \"\"\"\n",
        "                insert remove special characters\n",
        "\n",
        "                \"\"\"\n",
        "\n",
        "                # filter no meaning words\n",
        "                sen = remove_special_chars(sen, filter_chars)\n",
        "\n",
        "                # make sure a sentence have len(sentence) > 0\n",
        "                if len(sen)>0:\n",
        "                    data.append([each[0], sen, each[2]])\n",
        "\n",
        "        else:\n",
        "            data.append(each)\n",
        "\n",
        "    main_data = data[1:]\n",
        "    main_data = shuffle(main_data)\n",
        "    df = pd.DataFrame(main_data, columns = data[0])\n",
        "    return df\n",
        "\n",
        "# get data in a row\n",
        "def get_data(df, row = 60000):\n",
        "    return  df.iloc[row][0], df.iloc[row][1]\n",
        "\n",
        "# vectorize sentences and split it in to train and test file\n",
        "def vectorization(df, test_size=0.2):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(list(df[\"text\"]), list(df[\"language\"]), test_size=test_size, random_state=42)\n",
        "\n",
        "    # vectorize sentence X\n",
        "    count_vectorizer = CountVectorizer(analyzer='char')\n",
        "    X_train_features = count_vectorizer.fit_transform(X_train)\n",
        "    X_test_features = count_vectorizer.transform(X_test)\n",
        "\n",
        "    # vectorize label Y\n",
        "    label_encoder = preprocessing.LabelEncoder()\n",
        "    y_train_features = label_encoder.fit_transform(y_train)\n",
        "    y_test_features = label_encoder.transform(y_test)\n",
        "    \n",
        "    # getted features\n",
        "    features = count_vectorizer.get_feature_names()\n",
        "    \n",
        "    # getted labels\n",
        "    labels = list(label_encoder.classes_)\n",
        "    \n",
        "    return X_train_features, y_train_features, X_test_features, y_test_features, features, labels, count_vectorizer"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649664972449
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the Dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = open_file('formatted_data')\n",
        "df.shape\n",
        "label, text = get_data(df,row = 700)\n",
        "print(label)\n",
        "print(text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "da\ndesvã¦rre skete denne udvikling i europa hovedsageligt ved en stigning i produktiviteten og kun i ringe grad ved en stigning i beskã¦ftigelsen\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649665043172
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training & Testing Dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_features, y_train_features, X_test_features, y_test_features, features, labels, count_vectorizer = vectorization(df)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649665050674
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# number of the features\n",
        "print(\"features: \", features)\n",
        "print(\"\\nLen features: \", len(features))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "features:  [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x80', '\\x81', '\\x82', '\\x83', '\\x84', '\\x85', '\\x86', '\\x87', '\\x88', '\\x89', '\\x8a', '\\x8b', '\\x8c', '\\x8d', '\\x8e', '\\x8f', '\\x90', '\\x91', '\\x92', '\\x93', '\\x94', '\\x95', '\\x96', '\\x97', '\\x98', '\\x99', '\\x9a', '\\x9b', '\\x9c', '\\x9d', '\\x9e', '\\x9f', '\\xa0', '¡', '¢', '£', '¤', '¥', '¦', '¨', '©', 'ª', '¬', '\\xad', '®', '¯', '°', '±', '²', '³', '´', 'µ', '¶', '·', '¸', '¹', 'º', '¼', '½', '¾', '¿', 'â', 'ã', 'ä', 'å', 'è', 'î', 'ï', 'ð', 'ñ']\n\nLen features:  97\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649665051398
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_features.toarray()[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "array([8, 4, 1, 2, 0, 6, 0, 0, 0, 5, 0, 0, 3, 2, 4, 3, 2, 1, 5, 1, 5, 4,\n       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649665055016
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Development"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create and training model MultinomialNB\n",
        "modelNB = MultinomialNB()\n",
        "modelNB.fit(X_train_features, y_train_features)\n",
        "\n",
        "# model accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy: \",f1_score(y_test_features, modelNB.predict(X_test_features), average='macro'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy:  0.9253365038559969\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649665057693
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model Random Forest\n",
        "modelRF=RandomForestClassifier(n_estimators=100)\n",
        "modelRF.fit(X_train_features,y_train_features)\n",
        "\n",
        "y_pred = modelRF.predict(X_test_features)\n",
        "\n",
        "# model accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test_features, y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy: 0.9403787103377687\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649665132781
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Optimal Parameters for Random Forest using Grid Search CV"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tuning model by grid search cv\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = { \n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "CV_rfc = GridSearchCV(estimator=RandomForestClassifier(), n_jobs = -1, param_grid=param_grid, cv= 5)\n",
        "CV_rfc.fit(X_train_features, y_train_features)\n",
        "\n",
        "# choose the best parametters \n",
        "print(\"Optimal paras: \", CV_rfc.best_params_)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649666569967
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Optimal Parameters"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create random forest model with the optimal parametter\n",
        "optimal_modelRF=RandomForestClassifier(n_estimators=300, max_features= 'log2')\n",
        "\n",
        "#Train the model using the training sets \n",
        "optimal_modelRF.fit(X_train_features,y_train_features)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='log2',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=300,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649666774168
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find the accuracy\n",
        "y_pred = optimal_modelRF.predict(X_test_features)\n",
        "\n",
        "# model accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test_features, y_pred)) #Accuracy: 0.9437691914022518"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy: 0.9428096212896623\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649666775510
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_SVM = SVC(kernel='linear')\n",
        "model_SVM.fit(X_train_features, y_train_features)\n",
        "\n",
        "y_pred = model_SVM.predict(X_test_features)\n",
        "\n",
        "print(confusion_matrix(y_test_features,y_pred))\n",
        "print(classification_report(y_test_features,y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[ 669    3    0    8    0    0    2    0    0    0    0    0    0    0\n     0    2    0   12    0    0    0]\n [   6  515    0    2    0    0    3    0    1    1    0    0    1    1\n     0    0    0    3   14    2    0]\n [   1    0 1019    5    0    2    0    0    0    2    0    2    3   13\n     4    0    0    1    0    0    6]\n [   0    0   15  849    0    3    0    2    0    0    0    0    1    4\n    15    3    0    2    0    1    3]\n [   5    0    1    0  620    0    0    0    0    0    0    0    1    0\n     0    0    0    0    1    0    0]\n [   1    0    6    6    0  917    4    1    0    0    0    3    7    1\n     6    1    0    3    1    0    0]\n [   0    1    2    2    0   12  870    0    0    4    1   14    4    2\n     2    1   22    0    4    0    0]\n [   6    0    5    3    0    0    3  473   10    1    1    1    7    0\n     2    3    0    2    0    1    4]\n [   0    0    1    0    0    0    0   10  853    1    0    0    1    0\n     0    0    0    0    1    0    0]\n [   2    0    0    0    0    5   13    1    0  880    0   10    2    0\n     4    0    3    3    1    0    0]\n [   2    5    2    5    0    1    4    0    0    0  441    0    1    1\n     0    1    1    5    2    0    2]\n [   0    0    1    0    0    2    8    1    0    4    0  798    3    2\n     2    0    5    2    0    0    0]\n [   8    1    5    3    0    1    7    4    1    5    0    1  677    9\n     0    3    0    4    1    5    3]\n [  11    0    8    2    0    2    2    2    1    2    0    0   10  628\n     1    1    0    3    1    4    0]\n [   0    0   19   20    0   13    1    0    1    1    0    3    0    1\n  1005    0    0    0    0    6    4]\n [   5    0    0    1    0    7    3    2    0    1    0    0    4    0\n     1  472    0    2    0    1    0]\n [   0    0    0    0    0    2   40    0    0    7    0    0    2    2\n     0    0  819    2    1    0    1]\n [  14    2    1    6    0    3    8    0    0    4    0   11    1    3\n     3    2    2  430    0    0    0]\n [   7    8    0    3    0    3    4    3    0    1    3    1    4    1\n     1    0    2    2  453    6    0]\n [  10    2    1    3    0    1    3    2    0    2    0    1    6    3\n     5    1    1    3    3  498    0]\n [   0    0   13    4    0    1    0    4    0    3    0    1    2    4\n     3    1    0    2    0    0  851]]\n              precision    recall  f1-score   support\n\n           0       0.90      0.96      0.93       696\n           1       0.96      0.94      0.95       549\n           2       0.93      0.96      0.94      1058\n           3       0.92      0.95      0.93       898\n           4       1.00      0.99      0.99       628\n           5       0.94      0.96      0.95       957\n           6       0.89      0.92      0.91       941\n           7       0.94      0.91      0.92       522\n           8       0.98      0.98      0.98       867\n           9       0.96      0.95      0.95       924\n          10       0.99      0.93      0.96       473\n          11       0.94      0.96      0.95       828\n          12       0.92      0.92      0.92       738\n          13       0.93      0.93      0.93       678\n          14       0.95      0.94      0.94      1074\n          15       0.96      0.95      0.95       499\n          16       0.96      0.93      0.95       876\n          17       0.89      0.88      0.89       490\n          18       0.94      0.90      0.92       502\n          19       0.95      0.91      0.93       545\n          20       0.97      0.96      0.97       889\n\n    accuracy                           0.94     15632\n   macro avg       0.94      0.94      0.94     15632\nweighted avg       0.94      0.94      0.94     15632\n\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649666848501
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = list(df[\"text\"]), list(df[\"language\"])\n",
        "\n",
        "# vectorize sentence X\n",
        "vectorizer = CountVectorizer(analyzer='char')\n",
        "X_features = count_vectorizer.fit_transform(X)\n",
        "\n",
        "# vectorize label Y\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "Y_features = label_encoder.fit_transform(Y)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649666850654
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    RandomForestClassifier(n_estimators=200),\n",
        "    SVC(),\n",
        "    GaussianNB(),\n",
        "    LogisticRegression(),\n",
        "]\n",
        "CV = 5\n",
        "cv_df = pd.DataFrame(index=range(CV * len(models))) # no need\n",
        "entries = []"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649666850769
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model in models:\n",
        "    model_name = model.__class__.__name__\n",
        "    accuracies = cross_val_score(model, \n",
        "                                 X_features.toarray(), \n",
        "                                 Y_features, \n",
        "                                 scoring='accuracy', \n",
        "                                 cv=CV, \n",
        "                                 n_jobs=-1                                \n",
        "                                 )\n",
        "    print(accuracies)    \n",
        "    entries.append([model_name, sum(accuracies)/len(accuracies)])\n",
        "\n",
        "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy'])\n",
        "\n",
        "cv_df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649667166681
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}